{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image  # Used to Load the new image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# <<--- Preprocessing the Training set --->>\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),  \n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# <<--- Preprocessing the Test set --->>\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential() # Initialize CNN with sequence of layers\n",
    "\n",
    "# Make First convolutional_layer\n",
    "convolutional_layer = Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3])  # Make convolutional_layer\n",
    "cnn.add(convolutional_layer) # Add First Convolution Laeyer\n",
    "\n",
    "# Make Pooling Layer for first_convolutional_layer  \n",
    "pooling_layer = MaxPool2D(pool_size=2, strides=2)  # Make Max Pooling Layer\n",
    "cnn.add(pooling_layer)  # add Max Pooling layer to our model\n",
    "\n",
    "# Make Second convolutional_layer\n",
    "second_convolutional_layer = Conv2D(filters=32, kernel_size=3, activation='relu') # Make second_convolutional_layer \n",
    "cnn.add(second_convolutional_layer)  # add second_convolutional_layer\n",
    "\n",
    "# Make Pooling Layer for second_convolutional_layer  \n",
    "second_pooling_layer = MaxPool2D(pool_size=2, strides=2)  # Make second Max Pooling Layer\n",
    "cnn.add(second_pooling_layer)  # add second Max Pooling Layer\n",
    "\n",
    "# Add Flattening\n",
    "Flattening_layer = Flatten()  # Make Flattening layer\n",
    "cnn.add(Flattening_layer)  # add Fattening layer\n",
    "\n",
    "# Make Full Connected Hidden Layer\n",
    "full_connected_layer = Dense(units=128, activation='relu')  # Make full_connected_layer\n",
    "cnn.add(full_connected_layer)  # add full_connected_layer\n",
    "\n",
    "# Make Output Layer\n",
    "output_layer = Dense(units=1, activation='sigmoid')  # Make Output Layer\n",
    "cnn.add(output_layer)  # Add output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 192s 769ms/step - loss: 0.6856 - accuracy: 0.5610 - val_loss: 0.6279 - val_accuracy: 0.6570\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.6101 - accuracy: 0.6684 - val_loss: 0.5879 - val_accuracy: 0.6920\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.5653 - accuracy: 0.7070 - val_loss: 0.5293 - val_accuracy: 0.7425\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.5267 - accuracy: 0.7330 - val_loss: 0.5080 - val_accuracy: 0.7555\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.5017 - accuracy: 0.7527 - val_loss: 0.5721 - val_accuracy: 0.7270\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 50s 202ms/step - loss: 0.4934 - accuracy: 0.7615 - val_loss: 0.4957 - val_accuracy: 0.7610\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.4744 - accuracy: 0.7706 - val_loss: 0.5043 - val_accuracy: 0.7635\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.4533 - accuracy: 0.7855 - val_loss: 0.4666 - val_accuracy: 0.7875\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 47s 190ms/step - loss: 0.4466 - accuracy: 0.7861 - val_loss: 0.4853 - val_accuracy: 0.7765\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 46s 186ms/step - loss: 0.4374 - accuracy: 0.7940 - val_loss: 0.4449 - val_accuracy: 0.8065\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 47s 187ms/step - loss: 0.4207 - accuracy: 0.8037 - val_loss: 0.4669 - val_accuracy: 0.7810\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.4105 - accuracy: 0.8114 - val_loss: 0.4547 - val_accuracy: 0.7875\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 46s 184ms/step - loss: 0.3998 - accuracy: 0.8149 - val_loss: 0.4858 - val_accuracy: 0.7735\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.3980 - accuracy: 0.8176 - val_loss: 0.4382 - val_accuracy: 0.7940\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 46s 182ms/step - loss: 0.3715 - accuracy: 0.8354 - val_loss: 0.4711 - val_accuracy: 0.7845\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 46s 184ms/step - loss: 0.3713 - accuracy: 0.8359 - val_loss: 0.4610 - val_accuracy: 0.8010\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.3584 - accuracy: 0.8407 - val_loss: 0.4422 - val_accuracy: 0.8105curacy:  - ETA: 6s - l\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 47s 190ms/step - loss: 0.3506 - accuracy: 0.8450 - val_loss: 0.4734 - val_accuracy: 0.7910\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 50s 200ms/step - loss: 0.3298 - accuracy: 0.8568 - val_loss: 0.4407 - val_accuracy: 0.8110\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 46s 184ms/step - loss: 0.3198 - accuracy: 0.8581 - val_loss: 0.4605 - val_accuracy: 0.8135\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 49s 198ms/step - loss: 0.3140 - accuracy: 0.8614 - val_loss: 0.5045 - val_accuracy: 0.7865\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 0.3051 - accuracy: 0.8666 - val_loss: 0.4267 - val_accuracy: 0.8195\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 47s 186ms/step - loss: 0.2866 - accuracy: 0.8752 - val_loss: 0.4596 - val_accuracy: 0.8205\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.2835 - accuracy: 0.8767 - val_loss: 0.5372 - val_accuracy: 0.7990\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 46s 186ms/step - loss: 0.2694 - accuracy: 0.8815 - val_loss: 0.4830 - val_accuracy: 0.8165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x244a0b02508>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)  # Returns 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<-- Save Model in HDF5 file format -->>\n",
    "\n",
    "cnn.save(\"Model.h5\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
